{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mjYKjXLppRHl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skLhBHDWpZri",
        "outputId": "31d5b4ab-a03a-4dc9-b6f4-8287a202f657"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3JC_RjWOpdYh"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "true_news_path = './True.csv'\n",
        "fake_news_path = './Fake.csv'\n",
        "\n",
        "true_news_df = pd.read_csv(true_news_path)\n",
        "fake_news_df = pd.read_csv(fake_news_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nkn_qcNKp2Zm"
      },
      "outputs": [],
      "source": [
        "# combining datasets\n",
        "true_news_df['label'] = 1  # Label for true news\n",
        "fake_news_df['label'] = 0   # Label for fake news\n",
        "combined_df = pd.concat([true_news_df, fake_news_df], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "LraMV3O3p4k3",
        "outputId": "668bb9d9-c8a3-4fcd-b015-cd93160bcb72"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"combined_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"TREASON! HOW OBAMA\\u2019S SHADOW GOVERNMENT Is Commanding An Army Of Anti-Trump Agitators To Sabotage President Trump #WAR [VIDEO]\",\n          \"WHY TAXPAYER FUNDED FOOD TRUCKS PLAN TO STALK KIDS THIS SUMMER\",\n          \"WOW! HUNGARY\\u2019S PRIME MINISTER Follows Through On Promise To Build Border Wall\\u2026George Soros Will Be Furious When He Sees The STUNNING Number of Illegal Immigrants He\\u2019s Kept Out So Far\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"PAUL SPERRY SPOKE WITH LOU DOBBS ON HIS REPORT ABOUT OBAMA S SHADOW GOVERNMENT:Obama has two things going for him: The judiciary is his lethal weapon. He stacked the courts during his 8 years with liberal judges who can make things really difficult for President Trump. We ve seen it in action with the 9th Circuit Court of Appeals on Trump s Executive Order. President Trump should shake this court up ASAP! Yes, he can do it and he should! NEWT: JEFFERSON WOULD ABOLISH THE 9TH CIRCUIT COURT:The second thing that s troubling is the  shadow government  that Obama is setting up just blocks away from the White House. He s not going to let his  legacy  go down without a fight. He ll use the power of the evil doers like George Soros to pay for an army of destructive anarchists:PAUL SPERRY OF THE NYP: When former President Barack Obama said he was  heartened  by anti-Trump protests, he was sending a message of approval to his troops. Troops? Yes, Obama has an army of agitators   numbering more than 30,000   who will fight his Republican successor at every turn of his historic presidency. And Obama will command them from a bunker less than two miles from the White House.In what s shaping up to be a highly unusual post-presidency, Obama isn t just staying behind in Washington. He s working behind the scenes to set up what will effectively be a shadow government to not only protect his threatened legacy, but to sabotage the incoming administration and its popular  America First  agenda.He s doing it through a network of leftist nonprofits led by Organizing for Action. Normally you d expect an organization set up to support a politician and his agenda to close up shop after that candidate leaves office, but not Obama s OFA. Rather, it s gearing up for battle, with a growing war chest and more than 250 offices across the country.Since Donald Trump s election, this little-known but well-funded protesting arm has beefed up staff and ramped up recruitment of young liberal activists, declaring on its website,  We re not backing down.  Determined to salvage Obama s legacy, it s drawing battle lines on immigration, ObamaCare, race relations and climate change.Obama is intimately involved in OFA operations and even tweets from the group s account. In fact, he gave marching orders to OFA foot soldiers following Trump s upset victory. It is fine for everybody to feel stressed, sad, discouraged,  he said in a conference call from the White House.  But get over it.  He demanded they  move forward to protect what we ve accomplished. Now is the time for some organizing,  he said.  So don t mope. Far from sulking, OFA activists helped organize anti-Trump marches across US cities, some of which turned into riots. After Trump issued a temporary ban on immigration from seven terror-prone Muslim nations, the demonstrators jammed airports, chanting:  No ban, no wall, sanctuary for all! Run by old Obama aides and campaign workers, federal tax records show  nonpartisan  OFA marshals 32,525 volunteers nationwide. Registered as a 501(c)(4), it doesn t have to disclose its donors, but they ve been generous. OFA has raised more than $40 million in contributions and grants since evolving from Obama s campaign organization Obama for America in 2013.OFA, in IRS filings, says it trains young activists to develop  organizing skills.  Armed with Obama s 2012 campaign database, OFA plans to get out the vote for Democratic candidates it s grooming to win back Congress and erect a wall of resistance to Trump at the other end of Pennsylvania Avenue.It will be aided in that effort by the Obama Foundation, run by Obama s former political director, and the National Democratic Redistricting Committee, launched last month by Obama pal Eric Holder to end what he and Obama call GOP  gerrymandering  of congressional districts.Obama will be overseeing it all from a shadow White House located within two miles of Trump.DON T LET THE LEFT BE THE DEATH OF AMERICA! PLEASE DON T BE SILENT! SHOW UP AND SPEAK UP!\",\n          \"I wonder how many government funded trucks will be following Mooch s kids this summer? Oh, that s right she s a  good  mom. There s no need for government intervention Government-sponsored food trucks will be stalking students this summer with the goal of giving out thousands of  healthy  free lunches officials don t trust parents to provide.Officials at St. Paul public schools recently announced they re working with the local food bank Second Harvest to dispatch a mobile food truck to expand locations offering students free lunches during the summer. Last year the district supplied 71 locations, and the truck will help to add another 10 to 15 in 2015, KSTP reports.The district s director of nutrition services, Stacy Koppen, said the truck will drive around to different locations between 10:30 a.m. and 5 p.m. to help feed the city s needy youngsters. The truck will track down students at  spots like suggested basketball courts or fields where kids like to play,  according to the news site.The very expensive-looking specially rigged step van features a billboard with grinning teens alongside the message  Kids and teens: Get your free meals here.  The district apparently didn t offer the details on how the new program is financed, or how much the truck cost, and the news station didn t bother to ask. School officials said the truck will be manned by volunteers.Koppen said the district serves 29,000 lunches a day during the school year, but only 6,000 a day during the summer, so officials reasoned a truck is necessary to make sure students aren t starving. Time and again, we such a steep decline that we wonder,  Where are these children going? Are they getting the healthy, nutritious food they need for their health and academic success?  Koppen told KTSP. We want to make sure that when children return to school for the next school year, that they are at the optimal health status and that they are ready to learn,  she said, adding that the free food is available to all, not just low income kids.Minneapolis Public Schools have used food trucks to give away lunches since at least 2013. The Hopkins district in Minnesota, as well as districts in Colorado, New York, Massachusetts, Indiana, California, Tennessee, and other states have also launched trucks to take free food to students during the summer.In New York City, organizations can also apply to have school food trucks deliver meals to students on site upon request.Most, if not all, of the school food trucks seem to be funded at least in part by the U.S. Department of Agriculture, as part of the federal free and reduced-price school lunch program. Each summer, the United States Department of Agriculture reimburses school districts for all meals prepared and served at no cost to any child under the age of 18,  the Grand Junction Daily Sentinel reports.The news site explained that School District 51 expanded its free summer lunch program to dispatch a food truck to patrol local neighborhoods and seek out students. The USDA will pay for food and staff labor but not for the purchase of a food truck or the cost of running it,  according to the Daily Sentinel.In District 51, the cost of the truck and expenses are covered by a $50,000 grant from the Western Colorado Community Foundation.Via: EAG News\",\n          \"Hungary has slashed illegal immigration by over 99 per cent after rolling out a series of powerful border fences in response to the European migrant crisis, possibly providing a lesson as to the potential impact of constructing President Trump s much-discussed southern wall in the U.S.A razor-wire fence built along Hungary s southern border with Serbia and Croatia has helped to sharply reduce the number of migrants from the hundreds of thousands who last year moved up from the Balkans towards northern Europe, especially Germany.Hungary says it has registered 19,140 asylum applications in 2016 and more than 14,000 migrants have crossed its southern borders illegally.Speaking on the second anniversary of the government s move to seal Hungary s border with Serbia   which is also an external border for the European Union   Prime Minister Viktor Orb n s Chief Security Advisor Gy rgy Bakondi announced that the fences have caused illegal immigration to collapse from 391,000 in 2015, to 18,236 in 2016, to just 1,184 in 2017.In February 2017, Prime Minister Orb n took his war against George Soros public:Hungary s populist prime minister on Friday lashed out against billionaire financier George Soros, claiming he and groups backed by him want to secretly influence the country s politics.In his annual state of the nation speech, Viktor Orban said groups partly funded by Soros, who was born in Hungary, needed to be made transparent and identifiable. Large-bodied predators are swimming here in the waters. This is the trans-border empire of George Soros, with tons of money and international heavy artillery,  said Orban, who received a Soros-funded scholarship as Hungary was transitioning from communism to democracy in the late 1980s. It is causing trouble   that they are trying secretly and with foreign money to influence Hungarian politics,  Orban said.Breitbart:  The system of technical barriers is the key to the success of border security, and without it, it would be impossible to stop the mass arrival of immigrants , the security chief explained.Hungary had to respond rapidly to the migrant influx which burst upon Europe after Germany s Angela Merkel announced there was  no limit  on the number of asylum seekers her own country would accept, so its frontiers are defended by twin fences peppered with watchtowers and patrolled by thousands of newly recruited border guards rather than a solid wall   which would have taken longer to construct.Nevertheless, as it has been steadily reinforced illegal migration has slowed to a trickle   drawing the ire of open borders activists like billionaire financier George Soros and globalist officials at the European Union and the United Nations.In June 2017, Orb n told the Hungarian parliament that his country  will not give in to blackmail from Brussels and we reject the mandatory relocation quota.  Schulz shot back swiftly at Orb n in his speech on Tuesday.His comments came as the European Commission voted to launch infringement proceedings against the Czech Republic, Poland, and Hungary for not taking in refugees under a mandatory 2015 quota system advocated by Germany that aimed to relocate 160,000 refugees across the Continent.Hungary s badass Prime Minister Viktor Orb n has consistently stood up to leftist EU bullies who are demanding that all EU nations take their  fair share  of the mass influx of mostly Muslim refugees. We shall not allow others to tell us whom we can let into our home and country, whom we can live alongside.    Prime Minister Viktor Orb nWatch Prime Minister Viktor Orb n s historic speech in March 2016, where he demands other European leaders find their backbone and save Europe before it s too late. His speech will make you want to stand up and cheer! Mr.Orb n says  That s a German problem,  Schulz said.  Let me make this perfectly clear: When it comes to agricultural policy, it s all  Yes, please.  When it comes to subsidies, it s all  Yes, please.  And when it comes to solidarity in refugee policy, it s  No, thank you    that s not acceptable. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"left-news\",\n          \"Middle-east\",\n          \"worldnews\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Feb 12, 2017\",\n          \"May 29, 2015\",\n          \"Sep 16, 2017\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a7e58e03-5cb1-4397-927b-bfb2468ab8b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13534</th>\n",
              "      <td>France's Macron urges China, Russia to support...</td>\n",
              "      <td>PARIS (Reuters) - French President Emmanuel Ma...</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>November 29, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40567</th>\n",
              "      <td>TREASON! HOW OBAMA’S SHADOW GOVERNMENT Is Comm...</td>\n",
              "      <td>PAUL SPERRY SPOKE WITH LOU DOBBS ON HIS REPORT...</td>\n",
              "      <td>left-news</td>\n",
              "      <td>Feb 12, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31306</th>\n",
              "      <td>WOW! HUNGARY’S PRIME MINISTER Follows Through ...</td>\n",
              "      <td>Hungary has slashed illegal immigration by ove...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Sep 16, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44174</th>\n",
              "      <td>Black Politician Explains Why Left’s ‘Racist’ ...</td>\n",
              "      <td>Is the Democratic Party really the  party of t...</td>\n",
              "      <td>Middle-east</td>\n",
              "      <td>October 14, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43105</th>\n",
              "      <td>WHY TAXPAYER FUNDED FOOD TRUCKS PLAN TO STALK ...</td>\n",
              "      <td>I wonder how many government funded trucks wil...</td>\n",
              "      <td>left-news</td>\n",
              "      <td>May 29, 2015</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7e58e03-5cb1-4397-927b-bfb2468ab8b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7e58e03-5cb1-4397-927b-bfb2468ab8b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7e58e03-5cb1-4397-927b-bfb2468ab8b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9f5b0653-333e-4feb-b3d9-528827391419\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f5b0653-333e-4feb-b3d9-528827391419')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9f5b0653-333e-4feb-b3d9-528827391419 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                   title  \\\n",
              "13534  France's Macron urges China, Russia to support...   \n",
              "40567  TREASON! HOW OBAMA’S SHADOW GOVERNMENT Is Comm...   \n",
              "31306  WOW! HUNGARY’S PRIME MINISTER Follows Through ...   \n",
              "44174  Black Politician Explains Why Left’s ‘Racist’ ...   \n",
              "43105  WHY TAXPAYER FUNDED FOOD TRUCKS PLAN TO STALK ...   \n",
              "\n",
              "                                                    text      subject  \\\n",
              "13534  PARIS (Reuters) - French President Emmanuel Ma...    worldnews   \n",
              "40567  PAUL SPERRY SPOKE WITH LOU DOBBS ON HIS REPORT...    left-news   \n",
              "31306  Hungary has slashed illegal immigration by ove...     politics   \n",
              "44174  Is the Democratic Party really the  party of t...  Middle-east   \n",
              "43105  I wonder how many government funded trucks wil...    left-news   \n",
              "\n",
              "                     date  label  \n",
              "13534  November 29, 2017       1  \n",
              "40567        Feb 12, 2017      0  \n",
              "31306        Sep 16, 2017      0  \n",
              "44174    October 14, 2017      0  \n",
              "43105        May 29, 2015      0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HdRioACCp7SU"
      },
      "outputs": [],
      "source": [
        "# Define a function to clean the text\n",
        "def clean_text(text):\n",
        "    # Remove punctuation and special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "    return text\n",
        "\n",
        "# Apply the cleaning function to the 'text' column\n",
        "combined_df['cleaned_text'] = combined_df['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "kTUuce9Bqjrk",
        "outputId": "c7360bba-9869-47b4-d16b-00c734e9cf0e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'washington reuters head conservative republican faction us congress voted month huge expansion national debt pay tax cuts called fiscal conservative sunday urged budget restraint 2018 keeping sharp pivot way among republicans us representative mark meadows speaking cbs face nation drew hard line federal spending lawmakers bracing battle january return holidays wednesday lawmakers begin trying pass federal budget fight likely linked issues immigration policy even november congressional election campaigns approach republicans seek keep control congress president donald trump republicans want big budget increase military spending democrats also want proportional increases nondefense discretionary spending programs support education scientific research infrastructure public health environmental protection trump administration already willing say going increase nondefense discretionary spending 7 percent meadows chairman small influential house freedom caucus said program democrats saying thats enough need give government pay raise 10 11 percent fiscal conservative dont see rationale eventually run peoples money said meadows among republicans voted late december partys debtfinanced tax overhaul expected balloon federal budget deficit add 15 trillion 10 years 20 trillion national debt interesting hear mark talk fiscal responsibility democratic us representative joseph crowley said cbs crowley said republican tax bill would require united states borrow 15 trillion paid future generations finance tax cuts corporations rich one least fiscally responsible bills weve ever seen passed history house representatives think going paying many many years come crowley said republicans insist tax package biggest us tax overhaul 30 years boost economy job growth house speaker paul ryan also supported tax bill recently went meadows making clear radio interview welfare entitlement reform party often calls would top republican priority 2018 republican parlance entitlement programs mean food stamps housing assistance medicare medicaid health insurance elderly poor disabled well programs created washington assist needy democrats seized ryans early december remarks saying showed republicans would try pay tax overhaul seeking spending cuts social programs goals house republicans may take back seat senate votes democrats needed approve budget prevent government shutdown democrats use leverage senate republicans narrowly control defend discretionary nondefense programs social spending tackling issue dreamers people brought illegally country children trump september put march 2018 expiration date deferred action childhood arrivals daca program protects young immigrants deportation provides work permits president said recent twitter messages wants funding proposed mexican border wall immigration law changes exchange agreeing help dreamers representative debbie dingell told cbs favor linking issue policy objectives wall funding need daca clean said wednesday trump aides meet congressional leaders discuss issues followed weekend strategy sessions trump republican leaders jan 6 7 white house said trump also scheduled meet sunday florida republican governor rick scott wants emergency aid house passed 81 billion aid package hurricanes florida texas puerto rico wildfires california package far exceeded 44 billion requested trump administration senate yet voted aid'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_df['cleaned_text'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FP5TsV89qlo3"
      },
      "outputs": [],
      "source": [
        "# Initialize the tokenizer\n",
        "max_vocab_size = 10000\n",
        "tokenizer = Tokenizer(num_words=max_vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(combined_df['cleaned_text'])\n",
        "\n",
        "# Convert texts to sequences\n",
        "sequences = tokenizer.texts_to_sequences(combined_df['cleaned_text'])\n",
        "\n",
        "# Pad the sequences to ensure uniform input length\n",
        "max_sequence_length = 100\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "\n",
        "# Extract labels\n",
        "labels = combined_df['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIQQac6nquQv",
        "outputId": "d2d64f64-a820-40fe-93d1-c67514294a33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 31428\n",
            "Validation set size: 6735\n",
            "Test set size: 6735\n"
          ]
        }
      ],
      "source": [
        "# Splitting into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(padded_sequences, labels, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Check dataset sizes\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TPyx8MR8-IBI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "import gensim.downloader as api\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import re\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh46FbFeqxFu",
        "outputId": "a851e95c-1688-436a-8dce-2820c45cc3b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "Word2Vec model downloaded.\n"
          ]
        }
      ],
      "source": [
        "# Step 1.2: Download Pretrained Embeddings\n",
        "# 1.2.1 Word2Vec\n",
        "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
        "print(\"Word2Vec model downloaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syKvBcRn-Rf9",
        "outputId": "d251aca2-f862-46a4-9bbd-4e00a9c03025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n",
            "FastText model downloaded.\n"
          ]
        }
      ],
      "source": [
        "# 1.2.2 FastText\n",
        "fasttext_model = api.load(\"fasttext-wiki-news-subwords-300\")\n",
        "print(\"FastText model downloaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "MNqnbRJ7q0Cz"
      },
      "outputs": [],
      "source": [
        "# 1.2.3 GloVe\n",
        "glove_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "glove_zip_path = \"glove.6B.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezAP08wiAZ87",
        "outputId": "35ec8a17-09e0-46ae-a879-851fcf003f58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GloVe embeddings downloaded.\n"
          ]
        }
      ],
      "source": [
        "# Download GloVe embeddings\n",
        "response = requests.get(glove_url)\n",
        "with open(glove_zip_path, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "print(\"GloVe embeddings downloaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km1D6bpnAkFy",
        "outputId": "faee0be4-519c-4f05-aef9-294b3c8abc52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GloVe embeddings extracted.\n"
          ]
        }
      ],
      "source": [
        "# Unzip the downloaded file\n",
        "with zipfile.ZipFile(glove_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "print(\"GloVe embeddings extracted.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "X-Y1BoV-r4iZ"
      },
      "outputs": [],
      "source": [
        "# Clean up the zip file\n",
        "os.remove(glove_zip_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DLvJbBLoAjIy"
      },
      "outputs": [],
      "source": [
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(file_path):\n",
        "    embeddings_index = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index\n",
        "\n",
        "# Load GloVe embeddings (100d)\n",
        "glove_embeddings = load_glove_embeddings('/content/glove.6B.100d.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "aNdxRzOZBejo"
      },
      "outputs": [],
      "source": [
        "# Import the KeyedVectors class directly\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "def create_embedding_matrix(embeddings, tokenizer):\n",
        "    \"\"\"\n",
        "    Creates an embedding matrix for the given embeddings and tokenizer.\n",
        "\n",
        "    Args:\n",
        "        embeddings: A dictionary-like object containing word embeddings\n",
        "                    or a KeyedVectors object.\n",
        "        tokenizer: A Keras Tokenizer object.\n",
        "\n",
        "    Returns:\n",
        "        A NumPy array representing the embedding matrix.\n",
        "    \"\"\"\n",
        "    # Check if the embeddings object is a KeyedVectors instance\n",
        "    if isinstance(embeddings, KeyedVectors):\n",
        "        embedding_dim = embeddings.vector_size  # Get embedding dimension\n",
        "        embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
        "        for word, i in tokenizer.word_index.items():\n",
        "            if word in embeddings:  # Check if word is in vocabulary\n",
        "                embedding_matrix[i] = embeddings[word]\n",
        "    else:  # Assume it's a dictionary-like object\n",
        "        embedding_dim = len(next(iter(embeddings.values())))\n",
        "        embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
        "        for word, i in tokenizer.word_index.items():\n",
        "            if word in embeddings:\n",
        "                embedding_matrix[i] = embeddings[word]\n",
        "\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5_aOMaRpF68"
      },
      "outputs": [],
      "source": [
        "def create_embedding_matrix(embeddings, tokenizer):\n",
        "    \"\"\"\n",
        "    Creates an embedding matrix for the given embeddings and tokenizer.\n",
        "\n",
        "    Args:\n",
        "        embeddings: A dictionary-like object containing word embeddings\n",
        "                    or a KeyedVectors object or a numpy array.\n",
        "        tokenizer: A Keras Tokenizer object.\n",
        "\n",
        "    Returns:\n",
        "        A NumPy array representing the embedding matrix.\n",
        "    \"\"\"\n",
        "    # Check if the embeddings object is a KeyedVectors instance\n",
        "    if isinstance(embeddings, KeyedVectors):\n",
        "        embedding_dim = embeddings.vector_size  # Get embedding dimension\n",
        "        embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
        "        for word, i in tokenizer.word_index.items():\n",
        "            if word in embeddings:  # Check if word is in vocabulary\n",
        "                embedding_matrix[i] = embeddings[word]\n",
        "    # Check if the embeddings object is a numpy array\n",
        "    elif isinstance(embeddings, np.ndarray):\n",
        "        embedding_dim = embeddings.shape[1]  # Get embedding dimension from the array shape\n",
        "        embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
        "        # Here, we assume the embeddings are aligned with tokenizer.word_index\n",
        "        # i.e., embeddings[i] corresponds to the word with index i in tokenizer.word_index\n",
        "        for word, i in tokenizer.word_index.items():\n",
        "            if i < embeddings.shape[0]: # Make sure we don't go out of bounds\n",
        "                embedding_matrix[i] = embeddings[i]\n",
        "    else:  # Assume it's a dictionary-like object\n",
        "        embedding_dim = len(next(iter(embeddings.values())))\n",
        "        embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
        "        for word, i in tokenizer.word_index.items():\n",
        "            if word in embeddings:\n",
        "                embedding_matrix[i] = embeddings[word]\n",
        "\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Fl0zdiewBi47"
      },
      "outputs": [],
      "source": [
        "# Create embedding matrices\n",
        "word2vec_matrix = create_embedding_matrix(word2vec_model, tokenizer)\n",
        "fasttext_matrix = create_embedding_matrix(fasttext_model, tokenizer)\n",
        "glove_matrix = create_embedding_matrix(glove_embeddings, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "bIsLjqJjCWZl"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Step 2: Custom-Trained Embeddings\n",
        "\n",
        "# 2.1 Train Word2Vec\n",
        "custom_word2vec_model = Word2Vec(sentences=combined_df['cleaned_text'].apply(lambda x: x.split()), vector_size=100, window=5, min_count=1, workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "B9gb8eobC7h_"
      },
      "outputs": [],
      "source": [
        "# 2.2 Train FastText\n",
        "from gensim.models import FastText # Import the FastText class\n",
        "custom_fasttext_model = FastText(sentences=combined_df['cleaned_text'].apply(lambda x: x.split()), vector_size=100, window=5, min_count=1, workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbN0zPmOQ1ZR",
        "outputId": "b3cf29f5-e64c-4667-87c5-db15498ebf4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting glove-python3\n",
            "  Downloading glove_python3-0.1.0.tar.gz (326 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/327.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m235.5/327.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.0/327.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from glove-python3) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from glove-python3) (1.13.1)\n",
            "Building wheels for collected packages: glove-python3\n",
            "  Building wheel for glove-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glove-python3: filename=glove_python3-0.1.0-cp310-cp310-linux_x86_64.whl size=1064167 sha256=cfcf56b2c7218a26c14629fcfa068f031ebb7c4f4b6a9b80e2f5ced799d2cf58\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/2f/79/34314d44a0907e90e323c8c182ec23f126eb460829e02d98cf\n",
            "Successfully built glove-python3\n",
            "Installing collected packages: glove-python3\n",
            "Successfully installed glove-python3-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install glove-python3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlFefulhQuOo",
        "outputId": "d644cd9d-1380-42ca-fe35-6e9311506257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 4 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ]
        }
      ],
      "source": [
        "# 2.3 Train GloVe\n",
        "from glove import Corpus, Glove # Import Corpus and Glove from glove\n",
        "corpus = Corpus()\n",
        "corpus.fit(combined_df['cleaned_text'].apply(lambda x: x.split()), window=5)\n",
        "custom_glove_model = Glove(no_components=100, learning_rate=0.05)\n",
        "custom_glove_model.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)\n",
        "custom_glove_model.add_dictionary(corpus.dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "O4cqRYtoR7yt"
      },
      "outputs": [],
      "source": [
        "# 2.4 Save the Custom-Trained Embeddings\n",
        "custom_word2vec_model.save(\"custom_word2vec.model\")\n",
        "custom_fasttext_model.save(\"custom_fasttext.model\")\n",
        "custom_glove_model.save(\"custom_glove.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "1gEQXxuNt_x_"
      },
      "outputs": [],
      "source": [
        "# Step 3: Comparison\n",
        "# 3.1 Define a simple model to evaluate embeddings\n",
        "def create_model(embedding_matrix):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=embedding_matrix.shape[0], output_dim=embedding_matrix.shape[1], weights=[embedding_matrix], trainable=False))\n",
        "    model.add(LSTM(100, return_sequences=True))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbJJGYDAr7Yk",
        "outputId": "cb494089-6d3a-4334-ba8a-5b4afaba446a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "983/983 [==============================] - 153s 153ms/step - loss: 0.3129 - accuracy: 0.8542 - val_loss: 0.6819 - val_accuracy: 0.5157\n",
            "Epoch 2/5\n",
            "983/983 [==============================] - 150s 153ms/step - loss: 0.6820 - accuracy: 0.5219 - val_loss: 0.6387 - val_accuracy: 0.7163\n",
            "Epoch 3/5\n",
            "983/983 [==============================] - 149s 152ms/step - loss: 0.3331 - accuracy: 0.8125 - val_loss: 0.0149 - val_accuracy: 0.9966\n",
            "Epoch 4/5\n",
            "983/983 [==============================] - 150s 153ms/step - loss: 0.0171 - accuracy: 0.9966 - val_loss: 0.0188 - val_accuracy: 0.9969\n",
            "Epoch 5/5\n",
            "983/983 [==============================] - 149s 152ms/step - loss: 0.0158 - accuracy: 0.9968 - val_loss: 0.0186 - val_accuracy: 0.9963\n",
            "211/211 [==============================] - 9s 40ms/step - loss: 0.0203 - accuracy: 0.9964\n",
            "Word2Vec Pretrained Model - Loss: 0.0203133262693882, Accuracy: 0.9964365363121033\n",
            "Epoch 1/5\n",
            "983/983 [==============================] - 156s 155ms/step - loss: 0.5555 - accuracy: 0.6566 - val_loss: 0.2720 - val_accuracy: 0.9047\n",
            "Epoch 2/5\n",
            "983/983 [==============================] - 150s 153ms/step - loss: 0.4423 - accuracy: 0.7636 - val_loss: 0.6199 - val_accuracy: 0.6558\n",
            "Epoch 3/5\n",
            "983/983 [==============================] - 150s 153ms/step - loss: 0.2952 - accuracy: 0.9026 - val_loss: 0.1740 - val_accuracy: 0.9520\n",
            "Epoch 4/5\n",
            "983/983 [==============================] - 150s 153ms/step - loss: 0.2732 - accuracy: 0.8954 - val_loss: 0.3657 - val_accuracy: 0.8393\n",
            "Epoch 5/5\n",
            "983/983 [==============================] - 150s 153ms/step - loss: 0.1451 - accuracy: 0.9575 - val_loss: 0.0602 - val_accuracy: 0.9878\n",
            "211/211 [==============================] - 8s 39ms/step - loss: 0.0763 - accuracy: 0.9840\n",
            "FastText Pretrained Model - Loss: 0.0762600302696228, Accuracy: 0.9839643836021423\n",
            "Epoch 1/5\n",
            "983/983 [==============================] - 120s 118ms/step - loss: 0.3616 - accuracy: 0.8510 - val_loss: 0.1728 - val_accuracy: 0.9522\n",
            "Epoch 2/5\n",
            "983/983 [==============================] - 116s 118ms/step - loss: 0.3316 - accuracy: 0.8400 - val_loss: 0.0790 - val_accuracy: 0.9762\n",
            "Epoch 3/5\n",
            "983/983 [==============================] - 116s 118ms/step - loss: 0.0628 - accuracy: 0.9814 - val_loss: 0.0497 - val_accuracy: 0.9832\n",
            "Epoch 4/5\n",
            "983/983 [==============================] - 112s 114ms/step - loss: 0.0493 - accuracy: 0.9864 - val_loss: 0.0420 - val_accuracy: 0.9859\n",
            "Epoch 5/5\n",
            "983/983 [==============================] - 116s 118ms/step - loss: 0.0289 - accuracy: 0.9924 - val_loss: 0.0266 - val_accuracy: 0.9952\n",
            "211/211 [==============================] - 7s 35ms/step - loss: 0.0266 - accuracy: 0.9957\n",
            "GloVe Pretrained Model - Loss: 0.0265803299844265, Accuracy: 0.9956941604614258\n"
          ]
        }
      ],
      "source": [
        "# 3.2 Evaluate Pretrained Embeddings\n",
        "pretrained_models = {\n",
        "    \"Word2Vec\": create_model(word2vec_matrix),\n",
        "    \"FastText\": create_model(fasttext_matrix),\n",
        "    \"GloVe\": create_model(glove_matrix)\n",
        "}\n",
        "\n",
        "for name, model in pretrained_models.items():\n",
        "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5, batch_size=32)\n",
        "    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f\"{name} Pretrained Model - Loss: {loss}, Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F2dMItzuDn2",
        "outputId": "c8d9fd29-2873-4865-eebc-6125ef24a6e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "983/983 [==============================] - 120s 119ms/step - loss: 0.3682 - accuracy: 0.8230 - val_loss: 0.0509 - val_accuracy: 0.9901\n",
            "Epoch 2/5\n",
            "983/983 [==============================] - 117s 119ms/step - loss: 0.0421 - accuracy: 0.9922 - val_loss: 0.0236 - val_accuracy: 0.9964\n",
            "Epoch 3/5\n",
            "983/983 [==============================] - 116s 118ms/step - loss: 0.3401 - accuracy: 0.8113 - val_loss: 0.2478 - val_accuracy: 0.9042\n",
            "Epoch 4/5\n",
            "983/983 [==============================] - 116s 118ms/step - loss: 0.0671 - accuracy: 0.9858 - val_loss: 0.0387 - val_accuracy: 0.9926\n",
            "Epoch 5/5\n",
            "  9/983 [..............................] - ETA: 1:53 - loss: 0.0256 - accuracy: 0.9965"
          ]
        }
      ],
      "source": [
        "# 3.3 Evaluate Custom-Trained Embeddings\n",
        "custom_models = {\n",
        "    \"Custom Word2Vec\": create_model(create_embedding_matrix(custom_word2vec_model.wv.vectors, tokenizer)),\n",
        "    \"Custom FastText\": create_model(create_embedding_matrix(custom_fasttext_model.wv.vectors, tokenizer)),\n",
        "    \"Custom GloVe\": create_model(create_embedding_matrix(custom_glove_model.word_vectors, tokenizer))\n",
        "}\n",
        "\n",
        "for name, model in custom_models.items():\n",
        "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5, batch_size=32)\n",
        "    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f\"{name} Custom-Trained Model - Loss: {loss}, Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPLJbCdoyFC-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
